# TENSOR-DEFI: Whitepaper Claims vs Market Behavior

[![DOI](https://zenodo.org/badge/DOI/10.5281/zenodo.17917922.svg)](https://doi.org/10.5281/zenodo.17917922)
[![License: CC BY 4.0](https://img.shields.io/badge/License-CC%20BY%204.0-lightgrey.svg)](https://creativecommons.org/licenses/by/4.0/)
[![Python 3.9+](https://img.shields.io/badge/python-3.9+-blue.svg)](https://www.python.org/downloads/)

**Do Whitepaper Claims Predict Market Behavior? Evidence from Cryptocurrency Factor Analysis**

*Murad Farzulla • [Farzulla Research](https://farzulla.org) • December 2025*

---

## Overview

This research investigates whether functional claims in cryptocurrency whitepapers exhibit measurable alignment with subsequent market behavior patterns. We combine:

- **Zero-shot NLP classification** (BART-MNLI) to extract semantic features from whitepapers
- **CP tensor decomposition** to identify latent market factors
- **Procrustes analysis** with Tucker's congruence coefficient (φ) to measure alignment

### Key Findings

| Metric | Value |
|--------|-------|
| Claims-Statistics φ | **0.331** (moderate, p < 0.001) |
| Variance Explained | **92.45%** (rank-2 CP) |
| BTC Factor Loading | **28.5** (dominant outlier) |
| Assets Analyzed | 49 cryptocurrencies |
| Daily Observations | 17,543 (2020-2024) |

## Repository Structure

```
whitepaper-claims/
├── src/                      # Python modules
│   ├── alignment/           # Procrustes alignment methods
│   ├── nlp/                 # NLP classification pipeline
│   ├── tensor_ops/          # CP decomposition operations
│   ├── market/              # Market data processing
│   ├── visualization/       # Plotting utilities
│   └── stats/               # Statistical tests
├── scripts/                  # Analysis pipeline scripts
│   ├── run_full_pipeline.py # Complete end-to-end pipeline
│   ├── run_nlp.py           # NLP classification
│   ├── run_tensor.py        # Tensor construction
│   ├── run_alignment.py     # Factor alignment
│   └── run_figures.py       # Figure generation
├── paper/                    # LaTeX source
│   ├── main.tex             # Paper source
│   ├── references.bib       # Bibliography
│   └── figures/             # Paper figures
├── data/                     # Input data (included)
│   ├── whitepapers/         # PDF corpus
│   └── market/              # Parquet market data
├── outputs/                  # Pipeline outputs
│   ├── nlp/                 # NLP results (CSV)
│   ├── tensor/              # Tensor arrays (gitignored)
│   └── alignment/           # Alignment results (JSON)
├── figures/                  # Generated figures
├── CITATION.cff             # Citation metadata
├── requirements.txt         # Python dependencies
└── README.md                # This file
```

## Installation

```bash
# Clone repository
git clone https://github.com/studiofarzulla/whitepaper-claims.git
cd whitepaper-claims

# Create virtual environment
python -m venv venv
source venv/bin/activate  # Linux/Mac
# or: venv\Scripts\activate  # Windows

# Install dependencies
pip install -r requirements.txt
```

### Hardware Requirements

- **RAM:** 16GB minimum (32GB recommended for full tensor operations)
- **GPU:** Optional but recommended for NLP inference (CUDA/ROCm supported)
- **Storage:** ~200MB for full repository with data

## Data

This repository includes all data required for full reproducibility:

- **`data/whitepapers/`** - Cryptocurrency whitepaper PDFs (62MB)
- **`data/market/`** - Historical market data in Parquet format (24MB)
- **`outputs/nlp/`** - Pre-computed NLP classification results

Tensor outputs (`outputs/tensor/*.npy`) are gitignored but regenerated by the pipeline.

## Usage

### Full Pipeline

Run the complete analysis pipeline:

```bash
python scripts/run_full_pipeline.py
```

### Individual Steps

```bash
# 1. NLP classification of whitepapers
python scripts/run_nlp.py

# 2. Build market tensor
python scripts/run_tensor.py

# 3. Compute factor alignment
python scripts/run_alignment.py

# 4. Generate figures
python scripts/run_figures.py
```

### Pipeline Options

```bash
# Run with specific GPU device
CUDA_VISIBLE_DEVICES=0 python scripts/run_full_pipeline.py

# CPU-only mode
python scripts/run_full_pipeline.py --cpu
```

## Methodology

### 1. NLP Feature Extraction
Whitepapers are chunked and classified into 10 functional categories using zero-shot classification:
- Decentralization, Smart Contracts, DeFi, NFT/Gaming
- Medium of Exchange, Store of Value, Scalability
- Privacy, Interoperability, Governance

### 2. Tensor Construction
Market data forms a 4-way tensor: **(Time × Assets × Features × Statistics)**
- 17,543 daily observations
- 49 cryptocurrency assets
- 5 market features (price, volume, market cap, returns, volatility)

### 3. CP Decomposition
CANDECOMP/PARAFAC decomposition extracts rank-2 factors explaining 92.45% variance.

### 4. Alignment Measurement
Procrustes rotation aligns NLP-derived and market-derived factor spaces. Tucker's φ measures congruence.

## Citation

```bibtex
@article{farzulla2025tensor,
  title={Do Whitepaper Claims Predict Market Behavior? Evidence from Cryptocurrency Factor Analysis},
  author={Farzulla, Murad},
  journal={Zenodo},
  year={2025},
  doi={10.5281/zenodo.17917922}
}
```

## License

This work is licensed under [CC BY 4.0](https://creativecommons.org/licenses/by/4.0/).

## Contact

- **Author:** Murad Farzulla
- **ORCID:** [0009-0002-7164-8704](https://orcid.org/0009-0002-7164-8704)
- **Website:** [farzulla.org](https://farzulla.org)
- **GitHub:** [@studiofarzulla](https://github.com/studiofarzulla)

---

*Part of the [Farzulla Research](https://farzulla.org) initiative exploring computational methods in finance.*
