% ============================================================================
% ARCHIVED VERSION - DO NOT EDIT
% ============================================================================
% This file is the two-column ACM-style journal submission variant.
% It contains STALE DATA from the 24-whitepaper corpus.
%
% CANONICAL VERSION: main-arxiv.tex
%   - Single-column Palatino format
%   - 38-whitepaper expanded corpus
%   - Updated Ï† values and robustness sections
%   - Use for all arXiv/Zenodo submissions
%
% This file kept for reference only. Last updated: Feb 2026
% ============================================================================
%
% ============================================================================
% Do Whitepaper Claims Predict Market Behavior?
% Evidence from Cryptocurrency Factor Analysis
% ============================================================================
% Author: Murad Farzulla
% Organization: Farzulla Research
% Version: 3.0.0 (STALE - see main-arxiv.tex for current)
% Date: December 2025
% EXPANDED VERSION: 25+ pages with full methodology
% ============================================================================

\documentclass[11pt,twocolumn]{article}

% ============================================================================
% PACKAGE IMPORTS
% ============================================================================

\usepackage[a4paper, margin=0.9in]{geometry}
\usepackage{setspace}
\usepackage[T1]{fontenc}
\usepackage{lmodern}
\usepackage{graphicx}
\usepackage{float}
\usepackage{booktabs}
\usepackage{array}
\usepackage{longtable}
\usepackage{multirow}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{amsthm}
\usepackage{bm}
\usepackage[round,authoryear]{natbib}
\bibliographystyle{plainnat}
\usepackage{xcolor}
\definecolor{farzullaburgundy}{RGB}{128,0,32}
\definecolor{zenodoblue}{RGB}{0,123,255}
\definecolor{orcidgreen}{RGB}{166,206,57}
\usepackage{tcolorbox}
\usepackage{tikz}
\usepackage{scalerel}
% Algorithm pseudocode via tcolorbox (algorithm.sty not available)
\usepackage{url}
\usepackage[colorlinks=true,
            linkcolor=farzullaburgundy,
            citecolor=farzullaburgundy,
            urlcolor=farzullaburgundy,
            breaklinks=true,
            pdftitle={Do Whitepaper Claims Predict Market Behavior?},
            pdfauthor={Murad Farzulla},
            pdfkeywords={cryptocurrency, tensor decomposition, NLP, factor analysis}]{hyperref}

\def\UrlBreaks{\do\/\do-\do_}
\expandafter\def\expandafter\UrlBreaks\expandafter{\UrlBreaks\do\a\do\b\do\c\do\d\do\e\do\f\do\g\do\h\do\i\do\j\do\k\do\l\do\m\do\n\do\o\do\p\do\q\do\r\do\s\do\t\do\u\do\v\do\w\do\x\do\y\do\z}

\usepackage{titlesec}
\titlespacing*{\section}{0pt}{1.5ex plus 0.5ex minus 0.2ex}{1ex plus 0.2ex}
\titlespacing*{\subsection}{0pt}{1.2ex plus 0.4ex minus 0.2ex}{0.8ex plus 0.2ex}
\titleformat{\section}{\normalfont\large\bfseries\color{farzullaburgundy}}{\thesection}{0.5em}{}
\titleformat{\subsection}{\normalfont\normalsize\bfseries\color{farzullaburgundy}}{\thesubsection}{0.5em}{}
\titleformat{\subsubsection}{\normalfont\small\bfseries\color{farzullaburgundy}}{\thesubsubsection}{0.5em}{}

\usepackage{fancyhdr}

% Theorem environments
\newtheorem{definition}{Definition}
\newtheorem{theorem}{Theorem}
\newtheorem{proposition}{Proposition}

% Commands
\newcommand{\orcidicon}{\scalerel*{
    \begin{tikzpicture}[x=3ex,y=3ex]
    \draw[fill=orcidgreen] (0,0) circle (0.5);
    \end{tikzpicture}
}{\textrm{I}}}

\newcommand{\paperver}{3.0.0}
\newcommand{\paperdate}{December 2025}
\newcommand{\paperdoi}{10.5281/zenodo.17917922}

\newcommand{\metadatabox}[1]{%
\begin{tcolorbox}[
    colback=gray!5,
    colframe=farzullaburgundy,
    title=Publication Metadata,
    fonttitle=\bfseries,
    coltitle=white,
    colbacktitle=farzullaburgundy,
    width=\columnwidth,
    arc=2mm,
    boxrule=0.8pt
]
\small
\textbf{DOI:} \href{https://doi.org/#1}{\texttt{#1}}\\
\textbf{Version:} \paperver\\
\textbf{Date:} \paperdate\\
\textbf{License:} CC-BY-4.0
\end{tcolorbox}
}

\pagestyle{fancy}
\fancyhf{}
\fancyhead[L]{\small\href{https://farzulla.org}{farzulla.org}}
\fancyhead[R]{\small\href{https://doi.org/\paperdoi}{DOI: \paperdoi}}
\fancyfoot[C]{\small\thepage}
\fancyfoot[L]{\small Murad Farzulla}
\fancyfoot[R]{\small v\paperver~| \paperdate}
\renewcommand{\headrulewidth}{0.4pt}
\renewcommand{\footrulewidth}{0.4pt}

\fancypagestyle{firstpage}{
  \fancyhf{}
  \fancyfoot[C]{\small\thepage}
  \fancyfoot[L]{\small Murad Farzulla}
  \fancyfoot[R]{\small v\paperver~| \paperdate}
  \renewcommand{\headrulewidth}{0pt}
  \renewcommand{\footrulewidth}{0.4pt}
}

% ============================================================================
% DOCUMENT
% ============================================================================

\begin{document}

% Single-column frontmatter
\onecolumn
\setstretch{1.2}
\thispagestyle{firstpage}

\begin{center}
{\small\color{farzullaburgundy}\textbf{PREPRINT v\paperver} | \color{gray}Not peer-reviewed}
\end{center}
\vspace{0.5em}

\begin{center}
{\Large\bfseries Do Whitepaper Claims Predict Market Behavior?}\\[0.5em]
{\large\itshape Evidence from Cryptocurrency Factor Analysis}\\[1em]
{\bfseries Murad Farzulla}\textsuperscript{1} \href{https://orcid.org/0009-0002-7164-8704}{\orcidicon\ \texttt{0009-0002-7164-8704}}\\[0.5em]
{\small\itshape \textsuperscript{1}\href{https://farzulla.org}{Farzulla Research}}\\[0.3em]
{\small \paperdate}\\[0.5em]
{\small Correspondence: \href{mailto:murad@farzulla.org}{murad@farzulla.org}}
\end{center}

\begin{abstract}
\noindent Cryptocurrency projects articulate their value propositions through whitepapers, making foundational claims about functionality, use cases, and technical capabilities. This study investigates whether these narrative claims align with empirically observed market behavior. We construct a novel pipeline combining natural language processing (NLP) with tensor decomposition to compare three representational spaces: (1) a claims matrix derived from zero-shot classification of 38 whitepapers across 10 functional categories, (2) a market statistics matrix capturing 7 financial metrics for 49 cryptocurrency assets over two years of hourly data (17,543 timestamps), and (3) latent factors extracted via CP tensor decomposition (rank 2, explaining 92.5\% of variance). Using Procrustes rotation and Tucker's congruence coefficient ($\phi$), we test alignment between narrative and market spaces across 37 common entities.

Results indicate weak alignment: claims--statistics ($\phi = 0.246$, $p = 0.339$), claims--factors ($\phi = 0.058$, $p = 0.751$), and statistics--factors ($\phi = 0.174$, $p < 0.001$). Notably, the statistics--factors comparison achieves statistical significance despite weak magnitude, suggesting market statistics systematically relate to tensor-derived factors while narrative claims remain decoupled. Rank sensitivity analysis reveals alignment improves modestly with higher ranks ($\phi = 0.094$ at rank 5) but remains weak. Tucker decomposition comparison yields similar results ($\phi = 0.060$), confirming robustness to decomposition method. Cross-sectional analysis reveals XMR, CRV, YFI, and SOL exhibit positive alignment contributions ($+0.010$ to $+0.020$), while RPL ($-0.018$), HBAR ($-0.016$), and AAVE ($-0.011$) show the largest divergence. Temporal analysis across six rolling windows demonstrates moderate variation ($\phi = 0.162 \pm 0.026$). Feature importance ablation identifies medium of exchange, interoperability, and privacy claims as most predictive of market alignment.

We interpret these findings as evidence that whitepaper narratives are systematically poor predictors of realized market factor structure, with implications for narrative economics, market efficiency, and investment analysis in cryptocurrency markets.

\vspace{0.5em}
\noindent\textbf{Keywords:} Cryptocurrency, Tensor Decomposition, NLP, Factor Analysis, Procrustes Rotation, Tucker's Congruence Coefficient, Zero-Shot Classification

\vspace{0.3em}
\noindent\textbf{JEL Codes:} G14, G12, C38, C45
\end{abstract}

\vspace{1em}
\metadatabox{\paperdoi}

\vspace{1em}

\section*{Acknowledgements}

The author acknowledges Anthropic for developing Claude, whose assistance with pipeline development, mathematical exposition, and technical writing substantially accelerated this research. All errors, omissions, and interpretive limitations remain the author's responsibility.

\vspace{0.5em}
\noindent\textbf{Data \& Code:} Reproducible code and data are available at \href{https://github.com/studiofarzulla/tensor-defi}{\texttt{github.com/studiofarzulla/tensor-defi}}.

% ============================================================================
% MAIN BODY
% ============================================================================

\clearpage
\twocolumn
\setstretch{1.15}

\section{Introduction}

Cryptocurrency markets present a unique laboratory for studying the relationship between narrative and price. Unlike traditional equities, where value propositions emerge gradually through earnings reports and analyst coverage, cryptocurrency projects typically articulate comprehensive visions at inception through whitepapers. These foundational documents make explicit claims about functionality, use cases, and technical architecture---claims that should, in principle, relate to how assets behave in markets.

The efficient market hypothesis suggests that asset prices reflect available information \citep{fama1970efficient}. If whitepapers constitute meaningful information about project characteristics, we might expect narrative claims to align with market behavior. Conversely, \citet{shiller2017narrative} argues that ``narrative economics'' drives market dynamics through stories that spread virally, potentially decoupling prices from fundamentals.

This tension motivates our central research question: \textit{Do whitepaper claims predict market behavior?} Specifically, do the functional narratives articulated in project whitepapers align with empirically observed market factor structure?

We address this question through a novel methodological pipeline combining natural language processing with tensor decomposition. Our approach constructs three distinct representational spaces:

\begin{enumerate}
    \item A \textbf{claims matrix} $\mathbf{C} \in \mathbb{R}^{N \times K}$ derived from zero-shot classification of whitepaper text across $K = 10$ functional categories
    \item A \textbf{market statistics matrix} $\mathbf{S} \in \mathbb{R}^{M \times J}$ capturing $J = 7$ financial metrics across $M = 49$ assets
    \item \textbf{Latent factors} $\mathbf{F} \in \mathbb{R}^{M \times R}$ extracted from a high-dimensional market tensor via CP decomposition
\end{enumerate}

Using Procrustes rotation and Tucker's congruence coefficient, we then test whether these spaces align---whether assets that make similar claims exhibit similar market behavior.

Our findings reveal weak alignment across comparisons ($\phi < 0.30$), with one notable exception: the statistics--factors comparison achieves statistical significance ($p < 0.001$) despite weak magnitude, indicating systematic correspondence between market metrics and tensor-derived factors that narrative claims fail to capture. Specialized tokens (XMR, CRV, YFI, SOL) show positive alignment, while DeFi infrastructure tokens (RPL, HBAR, AAVE) exhibit the largest narrative-market divergence. This result is robust to temporal variation, subsample perturbation, decomposition method (CP vs Tucker), and rank selection.

\textbf{Contributions.} This paper makes four contributions: (1) we introduce a reproducible pipeline for comparing textual and market representational spaces in cryptocurrency research, (2) we provide detailed methodological exposition of tensor decomposition for factor extraction, (3) we deliver rigorous empirical evidence on the (mis)alignment between project narratives and market behavior, and (4) we demonstrate that null results in this domain constitute valid findings with implications for narrative economics.

The remainder of this paper is organized as follows. Section~\ref{sec:literature} reviews related work. Section~\ref{sec:data} describes our data sources. Section~\ref{sec:methodology} provides detailed methodology with full mathematical exposition. Section~\ref{sec:results} presents comprehensive results including sensitivity analyses. Section~\ref{sec:discussion} interprets findings, and Section~\ref{sec:conclusion} concludes.

\section{Related Work}
\label{sec:literature}

\subsection{Cryptocurrency Narratives and Sentiment}

Research on cryptocurrency narratives spans social media analysis, whitepaper studies, and sentiment measurement. \citet{chen2019bitcoin} show that Twitter sentiment predicts Bitcoin returns at short horizons, while \citet{ante2023tweet} find that Elon Musk's tweets generate significant abnormal returns for mentioned cryptocurrencies. \citet{haykir2022speculative} document speculative bubbles driven by narrative contagion across crypto assets. \citet{liu2021risks} establish that cryptocurrency returns exhibit momentum, size effects, and exposure to market-wide factors distinct from traditional assets.

Whitepaper analysis has received growing attention as a signal of project quality. \citet{howell2020initial} examine ICO whitepaper quality as a signal of project legitimacy, finding that technical depth correlates with fundraising success. \citet{fisch2019initial} show that whitepaper informativeness predicts ICO outcomes. \citet{adhami2018why} provide the first comprehensive empirical description of ICO determinants, finding that code availability, token presale, and utility design predict success. More recent work has applied sophisticated NLP to whitepaper content: \citet{thewissen2022unpacking} use topic modeling on 5,210 whitepapers to show that technical feature topics predict success while whitepaper informativeness diminishes post-listing. Critically, \citet{momtaz2021moral} demonstrates that issuers systematically exaggerate whitepaper claims---exaggeration raises funds short-term but causes token depreciation and platform failure long-term. \citet{samieifar2021read} find that whitepaper length and complexity correlate positively with funds raised, supporting signaling interpretations. \citet{florysiak2022experts} show that while expert ratings initially ``jam'' whitepaper signals, post-listing returns are better predicted by whitepaper content than analyst assessments. These studies focus on cross-sectional prediction at issuance; our work extends this by testing whether claims align with ongoing market factor structure.

\textbf{Narrative Economics Framework.} \citet{shiller2017narrative} provides the theoretical foundation for studying how narratives shape economic outcomes. This builds on foundational work in behavioral finance: \citet{baker2006investor} construct the canonical investor sentiment index, demonstrating that sentiment-driven mispricing is strongest for speculative, hard-to-value stocks---a category that includes most cryptocurrencies. \citet{baker2007investor} survey evidence on how sentiment affects both aggregate returns and cross-sectional pricing. \citet{tetlock2007giving} shows that media pessimism predicts market downturns and high trading volume, establishing the textual analysis framework for investor sentiment. Applied to cryptocurrency, this framework suggests that project narratives---embodied in whitepapers---should influence investor beliefs and thus market prices. Our study tests this prediction empirically, finding weak support for narrative-market coupling.

\textbf{Natural Language Processing in Finance.} The application of NLP to financial text has grown substantially, with transformer-based models enabling sophisticated document analysis \citep{loughran2020textual}. \citet{loughran2011when} demonstrate that general sentiment dictionaries misclassify financial text, motivating domain-specific approaches. \citet{kearney2014textual} provide a comprehensive methodological survey of textual sentiment methods and models. Domain-specific pre-training has proven effective: \citet{araci2019finbert} introduce FinBERT, outperforming Loughran-McDonald dictionaries on financial sentiment, while \citet{huang2020finbert} show similar gains on analyst reports. \citet{mishev2020evaluation} benchmark lexicons against transformers (BERT, FinBERT) across financial datasets, finding transformer superiority for nuanced sentiment. Zero-shot classification, as employed here, allows categorization without domain-specific training data \citep{lewis2020bart}. Our use of BART-MNLI represents a middle ground---leveraging powerful pre-trained representations while acknowledging potential limitations in cryptocurrency-specific semantics.

\textbf{Cryptocurrency Market Microstructure.} Beyond sentiment, cryptocurrency markets exhibit distinctive microstructure features: 24/7 trading, global fragmentation across exchanges, varying levels of market manipulation, and high correlation with Bitcoin. These features may dominate narrative effects. \citet{farzulla2025event} demonstrate that infrastructure disruption events generate significantly larger volatility responses than regulatory announcements, suggesting market participants weight technical fundamentals over policy uncertainty. This asymmetry---where operational failures matter more than regulatory shifts---implies that whitepaper claims about technical capabilities may warrant particular attention in volatility modeling. Our inclusion of multiple market statistics (volatility, liquidity, drawdown) attempts to capture this microstructure, but residual factors may remain.

\subsection{Factor Models in Cryptocurrency}

Traditional asset pricing employs factor models to explain cross-sectional return variation. \citet{fama1970efficient} established the theoretical foundation for efficient markets and factor-based returns. \citet{fama1993common} introduced the three-factor model for equities; analogous developments in cryptocurrency have emerged more recently.

\citet{liu2019common} establish the foundational three-factor model for cryptocurrency returns: market, size, and momentum. \citet{liu2021risks} extend this work, finding that these factors explain substantial cross-sectional variation analogous to Fama-French factors for equities. \citet{bianchi2021factor} apply Instrumented PCA (IPCA) to show that time-varying factor loadings outperform observable risk factors. \citet{dobrynskaya2020downside} extends crypto CAPM to include downside beta as a fourth factor, finding significant cross-sectional premia across 1,700 coins. \citet{bhambhwani2019blockchain} introduce blockchain-native factors---computing power, network size---as procyclical pricing factors with positive risk premia.

Our tensor decomposition implicitly captures similar factors---Factor 1 (dominated by Bitcoin) resembles the market factor, while Factor 2 may capture size or sector effects. These systematic factors may dominate any narrative-based signal, explaining why whitepaper claims fail to predict factor structure.

\textbf{Multi-Way Data in Finance.} Financial data naturally exhibits multi-way structure: assets $\times$ time $\times$ features. While matrix methods (PCA, factor analysis) collapse this structure, tensor decomposition preserves it. Our work contributes to the emerging literature applying tensor methods to financial data, demonstrating both their utility (interpretable factors) and limitations (weak alignment despite high explanatory power).

\subsection{Tensor Methods in Finance}

Tensor decomposition provides a natural framework for analyzing multi-way financial data. \citet{kolda2009tensor} provide a comprehensive review of tensor decomposition methods, establishing the theoretical foundations for CP and Tucker decomposition. Recent work has applied these methods to financial time series: \citet{chen2022tensor} develop tensor factor models for high-dimensional time series, introducing TIPUP/TOPUP estimators with explicit applications to economics and finance. \citet{wang2021tensor} apply Tucker decomposition to high-dimensional vector autoregression, demonstrating improved performance over matrix-based approaches for multivariate time series. \citet{han2023cp} develop CP factor models for dynamic tensors, providing uncorrelated latent factors directly applicable to asset pricing.

CP (CANDECOMP/PARAFAC) decomposition decomposes a tensor into rank-one components, extracting interpretable latent factors \citep{harshman1970foundations}. For market data structured as (time $\times$ asset $\times$ feature), CP decomposition yields asset-level factor loadings analogous to principal component analysis but preserving multi-way structure. Tucker decomposition offers an alternative with mode-specific ranks and a core tensor capturing interactions.

\subsection{Factor Comparison Methods}

Comparing factor structures across studies or datasets requires methods that account for rotational indeterminacy. Procrustes rotation \citep{schonemann1966generalized} finds the optimal orthogonal transformation aligning one factor matrix to another. \citet{brokken1983orthogonal} develops orthogonal Procrustes rotation that directly maximizes congruence, the approach we employ. Tucker's congruence coefficient ($\phi$) then measures similarity between aligned factors \citep{tucker1951method, lorenzo2006tuckers}.

\citet{korth1975distribution} establish null distributions for congruence coefficients from simulated data, essential for understanding what constitutes statistically meaningful alignment. \citet{paunonen1997factor} examines the distribution of factor congruence under chance conditions after Procrustes rotation, informing our significance testing. \citet{lorenzo2006tuckers} establish interpretation thresholds: $|\phi| \geq 0.95$ indicates factor equivalence, $|\phi| \geq 0.85$ indicates fair similarity, $|\phi| \geq 0.65$ indicates moderate similarity, and $|\phi| < 0.65$ indicates weak or no similarity. These thresholds guide our interpretation of narrative-market alignment.

\section{Data}
\label{sec:data}

\subsection{Market Data}

We collect hourly OHLCV (open, high, low, close, volume) data from Binance for 49 cryptocurrency assets spanning January 1, 2023 to December 31, 2024, yielding 17,543 timestamps per asset. Asset selection follows liquidity and data availability criteria, including major cryptocurrencies (BTC, ETH) and a diverse set of DeFi, infrastructure, and utility tokens.

Table~\ref{tab:data_summary} summarizes the dataset dimensions.

\begin{table}[H]
\centering
\caption{Dataset Summary}
\label{tab:data_summary}
\begin{tabular}{@{}lr@{}}
\toprule
\textbf{Dimension} & \textbf{Value} \\
\midrule
Assets (market data) & 49 \\
Assets (whitepapers) & 38 \\
Assets (common intersection) & 37 \\
Time period & Jan 2023 -- Dec 2024 \\
Timestamps (hourly) & 17,543 \\
Market features (OHLCV) & 5 \\
Derived statistics & 7 \\
Narrative categories & 10 \\
\bottomrule
\end{tabular}
\end{table}

\subsection{Whitepaper Corpus}

We collect whitepapers for 38 assets where official foundational documents are publicly available, spanning major cryptocurrencies (BTC, ETH, SOL), DeFi protocols (AAVE, UNI, MKR, CRV, YFI, SUSHI, COMP, SNX, LDO), infrastructure tokens (LINK, GRT, ENS, RPL), Layer 1/Layer 2 platforms (ADA, AVAX, DOT, ATOM, ALGO, NEAR, ICP, FIL, ARB, OP, HBAR, APT, SUI), and specialized tokens (XMR, ZEC, SC, STORJ, AR). Documents include original whitepapers, consensus papers, protocol specifications, and technical documentation. PDF text is extracted using PyPDF2 with sentence-level tokenization; for assets without extractable PDFs, we use official documentation in markdown format. Table~\ref{tab:whitepaper_corpus} summarizes corpus statistics for selected assets.

\begin{table}[H]
\centering
\caption{Whitepaper Corpus Statistics (Selected)}
\label{tab:whitepaper_corpus}
\begin{tabular}{@{}lrrl@{}}
\toprule
\textbf{Asset} & \textbf{Pages} & \textbf{Year} & \textbf{Type} \\
\midrule
ZEC & 229 & 2020 & Protocol Spec \\
STORJ & 90 & 2018 & Storage WP \\
ADA & 48 & 2020 & Consensus \\
ICP & 45 & 2021 & Tech Overview \\
LINK & 38 & 2017 & Oracle WP \\
FIL & 36 & 2017 & Tech Report \\
ETH & 36 & 2014 & Original WP \\
SOL & 32 & 2018 & Original WP \\
NEAR & 23 & 2020 & Sharding \\
MKR & 21 & 2017 & Stablecoin \\
XMR & 20 & 2013 & CryptoNote \\
\midrule
\multicolumn{4}{l}{\textit{+ 13 additional documents (see Appendix)}} \\
\bottomrule
\end{tabular}
\end{table}

The intersection of whitepaper and market data yields 37 common assets for alignment analysis (AR lacks sufficient market data coverage in our sample).

\section{Methodology}
\label{sec:methodology}

Our pipeline proceeds in five stages: (1) tensor construction, (2) tensor decomposition, (3) NLP claims extraction, (4) market statistics computation, and (5) Procrustes alignment with congruence testing.

\subsection{Tensor Construction}

\begin{definition}[Market Tensor]
A market tensor $\mathcal{X} \in \mathbb{R}^{T \times V \times A \times F}$ is a 4-way array with modes:
\begin{itemize}
    \item Time ($T = 17,543$ hourly timestamps)
    \item Venue ($V = 1$, Binance)
    \item Asset ($A = 49$ cryptocurrencies)
    \item Feature ($F = 5$, OHLCV)
\end{itemize}
\end{definition}

With a single venue, the effective structure is 3-way: $\mathcal{X} \in \mathbb{R}^{T \times A \times F}$. Each entry $x_{taf}$ represents the value of feature $f$ for asset $a$ at time $t$.

\subsection{Tensor Decomposition}

\subsubsection{CP Decomposition}

\begin{definition}[CP Decomposition]
The CANDECOMP/PARAFAC (CP) decomposition approximates a tensor as a sum of rank-one tensors:
\begin{equation}
\mathcal{X} \approx \sum_{r=1}^{R} \lambda_r \, \mathbf{a}_r \circ \mathbf{b}_r \circ \mathbf{c}_r
\end{equation}
where $\circ$ denotes outer product, $\lambda_r$ are weights, and $\mathbf{a}_r \in \mathbb{R}^T$, $\mathbf{b}_r \in \mathbb{R}^A$, $\mathbf{c}_r \in \mathbb{R}^F$ are mode-specific factor vectors.
\end{definition}

The factor matrices are:
\begin{align}
\mathbf{A} &= [\mathbf{a}_1 | \cdots | \mathbf{a}_R] \in \mathbb{R}^{T \times R} \quad \text{(time factors)} \\
\mathbf{B} &= [\mathbf{b}_1 | \cdots | \mathbf{b}_R] \in \mathbb{R}^{A \times R} \quad \text{(asset factors)} \\
\mathbf{C} &= [\mathbf{c}_1 | \cdots | \mathbf{c}_R] \in \mathbb{R}^{F \times R} \quad \text{(feature factors)}
\end{align}

The asset factor matrix $\mathbf{B}$ provides latent loadings for alignment testing.

\subsubsection{Alternating Least Squares}

CP decomposition is computed via alternating least squares (ALS):

\begin{tcolorbox}[colback=gray!5,colframe=farzullaburgundy,title={\textbf{Algorithm 1:} CP-ALS}]
\begin{tabular}{@{}ll@{}}
\textbf{1:} & Initialize $\mathbf{A}$, $\mathbf{B}$, $\mathbf{C}$ randomly \\
\textbf{2:} & \textbf{repeat} \\
\textbf{3:} & \quad $\mathbf{A} \gets \mathbf{X}_{(1)} (\mathbf{C} \odot \mathbf{B}) (\mathbf{C}^\top\mathbf{C} * \mathbf{B}^\top\mathbf{B})^{\dagger}$ \\
\textbf{4:} & \quad $\mathbf{B} \gets \mathbf{X}_{(2)} (\mathbf{C} \odot \mathbf{A}) (\mathbf{C}^\top\mathbf{C} * \mathbf{A}^\top\mathbf{A})^{\dagger}$ \\
\textbf{5:} & \quad $\mathbf{C} \gets \mathbf{X}_{(3)} (\mathbf{B} \odot \mathbf{A}) (\mathbf{B}^\top\mathbf{B} * \mathbf{A}^\top\mathbf{A})^{\dagger}$ \\
\textbf{6:} & \textbf{until} convergence
\end{tabular}
\end{tcolorbox}

where $\mathbf{X}_{(n)}$ is mode-$n$ matricization, $\odot$ is Khatri-Rao product, $*$ is Hadamard product, and $\dagger$ denotes pseudoinverse.

\subsubsection{Rank Selection}

We select rank $R$ to achieve target explained variance:
\begin{equation}
\text{EV}(R) = 1 - \frac{\|\mathcal{X} - \hat{\mathcal{X}}_R\|_F^2}{\|\mathcal{X} - \bar{x}\|_F^2}
\end{equation}

With target $\text{EV} \geq 0.90$, we obtain $R = 2$ (EV = 92.45\%).

\subsubsection{Tucker Decomposition}

For robustness, we also implement Tucker decomposition:
\begin{equation}
\mathcal{X} \approx \mathcal{G} \times_1 \mathbf{A} \times_2 \mathbf{B} \times_3 \mathbf{C}
\end{equation}
where $\mathcal{G} \in \mathbb{R}^{R_1 \times R_2 \times R_3}$ is the core tensor and $\times_n$ denotes mode-$n$ product.

\subsection{NLP Claims Extraction}

\subsubsection{Zero-Shot Classification}

We employ BART-large-MNLI \citep{lewis2020bart} for zero-shot text classification. Given a text segment $t$ and candidate labels $\{l_1, \ldots, l_K\}$, the model computes:
\begin{equation}
P(l_k | t) = \frac{\exp(s_k)}{\sum_{j=1}^K \exp(s_j)}
\end{equation}
where $s_k$ is the entailment score for label $l_k$.

\subsubsection{Functional Taxonomy}

Our taxonomy comprises $K = 10$ categories motivated by cryptocurrency use-case literature (Table~\ref{tab:taxonomy}).

\begin{table}[t]
\centering
\small
\caption{Functional Category Taxonomy}
\label{tab:taxonomy}
\begin{tabular}{@{}p{2.2cm}p{4cm}@{}}
\toprule
\textbf{Category} & \textbf{Keywords} \\
\midrule
store\_of\_value & Digital gold, wealth \\
medium\_of\_exchange & Payments, currency \\
smart\_contracts & Programmable logic, dApps \\
defi & Lending, yield farming \\
governance & Voting, DAOs \\
scalability & Throughput, L2 \\
privacy & Anonymity, ZK proofs \\
interoperability & Cross-chain, bridges \\
data\_storage & Decentralized storage \\
oracle & External data feeds \\
\bottomrule
\end{tabular}
\end{table}

\subsubsection{Aggregation}

For each asset $n$, we aggregate classification scores across text chunks:
\begin{equation}
c_{nk} = \frac{1}{|T_n|} \sum_{t \in T_n} P(l_k | t)
\end{equation}
yielding claims matrix $\mathbf{C} \in \mathbb{R}^{N \times K}$.

\subsection{Market Statistics}

We compute seven z-normalized summary statistics for each asset:

\begin{enumerate}
    \item \textbf{Mean return}: $\bar{r}_a = \frac{1}{T} \sum_t r_{at}$
    \item \textbf{Volatility}: $\sigma_a = \sqrt{\frac{1}{T-1} \sum_t (r_{at} - \bar{r}_a)^2}$
    \item \textbf{Sharpe ratio}: $\text{SR}_a = \frac{\bar{r}_a}{\sigma_a} \cdot \sqrt{252 \cdot 24}$
    \item \textbf{Max drawdown}: $\text{MDD}_a = \min_t \frac{P_t - \max_{s \leq t} P_s}{\max_{s \leq t} P_s}$
    \item \textbf{Avg volume}: $\bar{V}_a = \frac{1}{T} \sum_t V_{at}$
    \item \textbf{Vol-of-vol}: $\sigma_{\sigma,a}$ (rolling volatility std)
    \item \textbf{Trend}: $\beta_a$ from $P_t = \alpha + \beta t + \epsilon$
\end{enumerate}

This yields statistics matrix $\mathbf{S} \in \mathbb{R}^{M \times 7}$.

\subsection{Procrustes Alignment}

\subsubsection{Problem Formulation}

\begin{definition}[Orthogonal Procrustes Problem]
Given matrices $\mathbf{A}, \mathbf{B} \in \mathbb{R}^{n \times p}$, find orthogonal $\mathbf{Q} \in \mathbb{R}^{p \times p}$ minimizing:
\begin{equation}
\min_{\mathbf{Q}^\top\mathbf{Q} = \mathbf{I}} \|\mathbf{A}\mathbf{Q} - \mathbf{B}\|_F^2
\end{equation}
\end{definition}

\subsubsection{SVD Solution}

\begin{theorem}[\citealt{schonemann1966generalized}]
The optimal rotation is $\mathbf{Q}^* = \mathbf{V}\mathbf{U}^\top$ where $\mathbf{U}\mathbf{\Sigma}\mathbf{V}^\top = \text{SVD}(\mathbf{A}^\top\mathbf{B})$.
\end{theorem}

\begin{proof}
See Appendix~\ref{app:procrustes}.
\end{proof}

\subsubsection{Dimension Handling}

When comparing matrices of different column dimensions, we zero-pad the smaller matrix to match dimensions before alignment.

\subsection{Tucker's Congruence Coefficient}

\begin{definition}[Tucker's $\phi$]
The congruence coefficient between vectors $\mathbf{x}, \mathbf{y} \in \mathbb{R}^n$ is:
\begin{equation}
\phi(\mathbf{x}, \mathbf{y}) = \frac{\sum_{i=1}^n x_i y_i}{\sqrt{\sum_{i=1}^n x_i^2 \cdot \sum_{i=1}^n y_i^2}}
\end{equation}
\end{definition}

This equals cosine similarity without mean-centering, appropriate for factor comparison where sign and magnitude both carry meaning.

\subsubsection{Matrix Congruence}

For matrices $\mathbf{A}, \mathbf{B}$ after Procrustes alignment, we compute per-column $\phi$ values and report mean absolute $\phi$:
\begin{equation}
\bar{\phi} = \frac{1}{p} \sum_{j=1}^p |\phi(\mathbf{a}_j, \mathbf{b}_j)|
\end{equation}

\subsubsection{Interpretation Thresholds}

Following \citet{lorenzo2006tuckers}:
\begin{itemize}
    \item $|\phi| \geq 0.95$: Factor equivalence
    \item $|\phi| \geq 0.85$: Fair similarity
    \item $|\phi| \geq 0.65$: Moderate similarity
    \item $|\phi| < 0.65$: Weak/no similarity
\end{itemize}

\subsection{Statistical Inference}

\subsubsection{Permutation Test}

We assess significance via permutation:
\begin{enumerate}
    \item Compute observed $\phi^*$
    \item For $b = 1, \ldots, B$ permutations: permute rows of $\mathbf{B}$, compute $\phi^{(b)}$
    \item $p$-value $= \frac{1}{B} \sum_{b=1}^B \mathbf{1}[\phi^{(b)} \geq \phi^*]$
\end{enumerate}

\subsubsection{Bootstrap Confidence Intervals}

We construct 95\% CIs via bootstrap resampling with replacement, taking percentiles of the bootstrap distribution.

\section{Results}
\label{sec:results}

\subsection{Tensor Decomposition}

CP decomposition with rank 2 explains 92.45\% of tensor variance. Figure~\ref{fig:tensor_slice} visualizes a cross-sectional slice of the market tensor.

\begin{figure}[H]
    \centering
    \includegraphics[width=\columnwidth]{figures/fig10_tensor_slice.pdf}
    \caption{Market tensor slice (asset $\times$ feature) at mid-sample timestamp. Values are z-normalized. Structure reveals asset clusters and feature correlations.}
    \label{fig:tensor_slice}
\end{figure}

Factor loadings reveal BTC as a massive outlier (Factor 1 loading = 28.5, compared to mean $\approx 0$). Figure~\ref{fig:factor_scatter} shows assets in factor space.

\begin{figure}[H]
    \centering
    \includegraphics[width=\columnwidth]{figures/fig6_factor_scatter.pdf}
    \caption{Assets in CP factor space (rank 2). BTC, GALA, and SC are statistical outliers ($>2\sigma$). Colors indicate clusters from cross-sectional analysis.}
    \label{fig:factor_scatter}
\end{figure}

\subsection{Claims Matrix}

Figure~\ref{fig:claims} displays the claims matrix heatmap. Bitcoin emphasizes ``store of value'' and ``medium of exchange,'' while Ethereum and Solana concentrate on ``smart contracts'' and ``scalability.''

\begin{figure}[H]
    \centering
    \includegraphics[width=\columnwidth]{figures/fig1_claims_heatmap.pdf}
    \caption{Claims matrix: Zero-shot classification scores across 38 assets and 10 functional categories.}
    \label{fig:claims}
\end{figure}

\subsection{Primary Alignment Tests}

Table~\ref{tab:alignment} reports alignment results for three comparisons.

\begin{table}[H]
\centering
\small
\caption{Primary Alignment Test Results ($n = 37$)}
\label{tab:alignment}
\begin{tabular}{@{}lcccc@{}}
\toprule
\textbf{Comparison} & $\boldsymbol{\phi}$ & \textbf{CI} & \textbf{p} & \\
\midrule
Claims--Stats & 0.246 & [.24,.38] & 0.339 & Weak \\
Claims--Factors & 0.058 & [.05,.15] & 0.751 & Weak \\
Stats--Factors & 0.174 & [.14,.22] & $<$0.001 & Weak* \\
\bottomrule
\end{tabular}
\end{table}

\noindent\textit{*Statistically significant despite weak magnitude.}

\vspace{0.5em}
All three comparisons yield weak alignment ($\phi < 0.30$). Notably, the statistics--factors comparison achieves statistical significance ($p < 0.001$) despite weak magnitude, indicating systematic correspondence between market metrics and tensor-derived factors. Claims-based comparisons show no significant alignment, suggesting narrative content fails to predict either market statistics or latent factors.

\subsection{Rank Sensitivity Analysis}

Figure~\ref{fig:rank_sensitivity} shows how alignment varies with CP rank.

\begin{figure}[H]
    \centering
    \includegraphics[width=\columnwidth]{figures/fig7_rank_sensitivity.pdf}
    \caption{Rank sensitivity: Explained variance and alignment $\phi$ vs CP rank. Variance jumps at rank 2; alignment improves gradually.}
    \label{fig:rank_sensitivity}
\end{figure}

Table~\ref{tab:rank_sensitivity} details rank sensitivity results.

\begin{table}[H]
\centering
\caption{Rank Sensitivity Analysis}
\label{tab:rank_sensitivity}
\begin{tabular}{@{}ccc@{}}
\toprule
\textbf{Rank} & \textbf{Variance} & $\boldsymbol{\phi}$ \\
\midrule
1 & 79.4\% & 0.036 \\
2 & 92.5\% & 0.058 \\
3 & 92.5\% & 0.073 \\
4 & 98.1\% & 0.094 \\
5 & 98.1\% & 0.094 \\
\bottomrule
\end{tabular}
\end{table}

Alignment peaks at ranks 4--5 ($\phi \approx 0.094$), suggesting diminishing returns from additional factors. Even at optimal rank, alignment remains well below the 0.65 threshold for moderate similarity.

\subsection{Tucker vs CP Comparison}

Table~\ref{tab:tucker_cp} compares decomposition methods.

\begin{table}[H]
\centering
\caption{Tucker vs CP Decomposition Comparison}
\label{tab:tucker_cp}
\begin{tabular}{@{}lccc@{}}
\toprule
\textbf{Method} & \textbf{Ranks} & \textbf{Variance} & $\boldsymbol{\phi}$ \\
\midrule
CP & 2 & 92.45\% & 0.058 \\
Tucker & [5,2,2] & 92.46\% & 0.060 \\
\bottomrule
\end{tabular}
\end{table}

Both methods achieve nearly identical variance explained and alignment. Tucker yields marginally higher alignment ($\phi = 0.060$ vs $0.058$), but both indicate weak narrative-factor correspondence, confirming robustness to decomposition choice.

\subsection{Per-Dimension Alignment}

Figure~\ref{fig:dimension_alignment} shows per-dimension $\phi$ values for the claims--statistics comparison.

\begin{figure}[H]
    \centering
    \includegraphics[width=\columnwidth]{figures/fig5_dimension_alignment.pdf}
    \caption{Per-dimension alignment (Claims--Statistics). No dimension reaches the 0.85 threshold for similarity.}
    \label{fig:dimension_alignment}
\end{figure}

Dimension 5 (governance) shows highest alignment ($\phi = 0.577$), approaching moderate similarity, while three dimensions show zero alignment due to padding.

\subsection{Temporal Stability}

Figure~\ref{fig:temporal} shows alignment evolution across six rolling windows.

\begin{figure}[H]
    \centering
    \includegraphics[width=\columnwidth]{figures/fig4_temporal_phi.pdf}
    \caption{Temporal evolution of alignment coefficient across 6-month rolling windows (3-month stride).}
    \label{fig:temporal}
\end{figure}

Mean $\phi = 0.162 \pm 0.026$ across windows. Alignment shows moderate variation throughout the sample period, ranging from $\phi = 0.138$ (mid-2023) to $\phi = 0.200$ (late 2023). The expanded corpus ($n = 37$) improves statistical power while revealing greater temporal heterogeneity.

\subsection{Entity-Level Analysis}

Figure~\ref{fig:entity_impact} shows leave-one-out entity impact.

\begin{figure}[H]
    \centering
    \includegraphics[width=\columnwidth]{figures/fig9_entity_impact.pdf}
    \caption{Entity impact on alignment ($n = 37$). Privacy and DeFi tokens (XMR, CRV, YFI, SOL) help alignment; DeFi infrastructure tokens (SUSHI, AAVE, HBAR, RPL) hurt alignment.}
    \label{fig:entity_impact}
\end{figure}

Table~\ref{tab:entity_impact} provides entity rankings for the top and bottom contributors.

\begin{table}[H]
\centering
\caption{Entity Impact Analysis (Top/Bottom)}
\label{tab:entity_impact}
\begin{tabular}{@{}lrl@{}}
\toprule
\textbf{Asset} & \textbf{Impact} & \textbf{Interpretation} \\
\midrule
XMR & $+0.020$ & Helps \\
CRV & $+0.013$ & Helps \\
YFI & $+0.012$ & Helps \\
SOL & $+0.010$ & Helps \\
\midrule
LINK & $-0.010$ & Neutral \\
SUSHI & $-0.011$ & Hurts \\
AAVE & $-0.011$ & Hurts \\
HBAR & $-0.016$ & Hurts \\
RPL & $-0.018$ & Hurts \\
\bottomrule
\end{tabular}
\end{table}

Notably, privacy-focused XMR shows the strongest positive impact ($+0.020$), followed by DeFi yields (CRV, YFI) and SOL. RPL shows the largest negative impact ($-0.018$), followed by HBAR ($-0.016$). The pattern suggests specialized tokens with distinct market niches align better with their whitepaper claims than broad DeFi infrastructure tokens.

\subsection{Feature Importance}

Figure~\ref{fig:feature_importance} shows ablation-based feature importance.

\begin{figure}[H]
    \centering
    \includegraphics[width=\columnwidth]{figures/fig8_feature_importance.pdf}
    \caption{Feature importance via ablation. Medium of exchange, interoperability, and privacy claims contribute most to alignment.}
    \label{fig:feature_importance}
\end{figure}

Table~\ref{tab:feature_importance} details importance values.

\begin{table}[H]
\centering
\caption{Feature Importance (Ablation)}
\label{tab:feature_importance}
\begin{tabular}{@{}lr@{}}
\toprule
\textbf{Category} & \textbf{Impact} \\
\midrule
medium\_of\_exchange & $+0.021$ \\
interoperability & $+0.017$ \\
privacy & $+0.017$ \\
smart\_contracts & $+0.013$ \\
oracle & $+0.008$ \\
governance & $+0.005$ \\
defi & $+0.002$ \\
store\_of\_value & $+0.000$ \\
scalability & $+0.000$ \\
data\_storage & $-0.001$ \\
\bottomrule
\end{tabular}
\end{table}

Monetary claims (medium\_of\_exchange) contribute most to alignment ($+0.021$), followed by interoperability and privacy. Data storage shows the only negative impact ($-0.001$), though minimal. This suggests market behavior is best predicted by core transactional and infrastructure claims.

\subsection{Robustness Checks}

Bootstrap resampling (100 iterations, 80\% subsample) yields mean $\phi = 0.265 \pm 0.017$ with 95\% CI $[0.235, 0.298]$. The point estimate slightly exceeds the full-sample result ($\phi = 0.246$) but remains firmly in the ``weak'' range, with the upper confidence bound well below the 0.65 threshold for moderate similarity.

\section{Discussion}
\label{sec:discussion}

\subsection{Interpreting the Null Result}

Our central finding is negative: whitepaper claims do not meaningfully predict market factor structure. This null result admits several interpretations.

First, whitepapers may represent aspirational narratives rather than realized functionality. Projects articulate visions at inception that evolve, pivot, or fail to materialize. Bitcoin's ``peer-to-peer electronic cash'' framing diverged significantly from its ``digital gold'' market reality.

Second, market behavior may be driven by factors orthogonal to functional claims. Speculation, liquidity provision, correlation with Bitcoin, and macroeconomic factors dominate cryptocurrency price dynamics \citep{liu2021risks}, potentially swamping any signal from project-specific narratives.

Third, our NLP pipeline may fail to capture narrative nuance. Zero-shot classification, while scalable, may miss domain-specific semantics that differentiate projects.

\subsection{Specialized Token Alignment}

In the expanded corpus ($n = 37$), Bitcoin shows modest negative alignment ($-0.004$), while the largest positive contributors are specialized tokens: XMR ($+0.020$), CRV ($+0.013$), YFI ($+0.012$), and SOL ($+0.010$). Bitcoin's dominant market position ($>5\sigma$ outlier in Factor 1) creates statistical leverage, but its alignment contribution is relatively neutral compared to major DeFi infrastructure tokens. The expanded corpus reveals that tokens with distinct market niches (privacy, yield aggregation, high-performance L1) whose whitepapers articulate specific use cases better predict their market behaviors.

\subsection{DeFi Divergence}

DeFi infrastructure tokens (RPL, HBAR, AAVE, SUSHI) show the largest narrative-market gaps ($-0.011$ to $-0.018$). RPL's divergence ($-0.018$) reflects the disconnect between liquid staking narratives and realized market dynamics. HBAR's negative contribution ($-0.016$) suggests enterprise-focused claims poorly predict retail-driven trading patterns. These projects make complex claims about financial primitives and infrastructure that may not map cleanly onto standard market behavior metrics. DeFi token prices depend heavily on protocol-specific factors (TVL, fee revenue, governance activity) not captured in our summary statistics.

\subsection{Feature Importance Patterns}

Monetary claims (medium\_of\_exchange) contribute most to alignment ($+0.021$), followed by interoperability ($+0.017$) and privacy ($+0.017$). This pattern suggests markets reward projects with clear transactional and cross-chain value propositions. Data storage shows the only negative impact ($-0.001$), though minimal. Projects emphasizing core monetary and infrastructure functionality exhibit better narrative-market correspondence than those with diffuse technical claims.

\subsection{Theoretical Implications}

Our findings contribute to the growing literature on narrative economics \citep{shiller2017narrative} by providing quantitative evidence on the limits of narrative-market coupling in cryptocurrency markets. Three theoretical implications emerge:

\textbf{Narrative Dissociation Hypothesis.} The weak alignment we document suggests that cryptocurrency markets operate under what we term ``narrative dissociation''---a systematic decoupling between stated project intentions and realized market behavior. This contrasts with efficient market theory, which would predict that informative narratives are rapidly incorporated into prices. Instead, our findings suggest that either narratives contain little price-relevant information, or markets systematically ignore such information.

\textbf{Factor Structure Independence.} The orthogonality of narrative space to market factor space implies that the latent factors driving cryptocurrency returns are fundamentally different from the functional dimensions projects emphasize. Market factors appear to capture systemic exposures (Bitcoin correlation, liquidity risk, macro sensitivity) rather than project-specific functionality. This has implications for portfolio construction: diversification along narrative dimensions may not reduce factor exposure.

\textbf{Bounded Rationality in Crypto Markets.} The persistence of elaborate whitepaper narratives despite their apparent irrelevance to market outcomes suggests bounded rationality among market participants. Investors may allocate attention to narratives as heuristics, even when such narratives lack predictive power. This parallels findings in behavioral finance on the role of stories in investment decisions.

\subsection{Comparison with Prior Literature}

Our null result stands in contrast to studies finding significant sentiment-return relationships in cryptocurrency markets \citep{chen2019bitcoin, ante2023tweet}. However, these studies examine \textit{contemporaneous} sentiment on social media, which may capture short-term market dynamics, while we examine \textit{static} whitepaper content, which represents founding narratives. The discrepancy suggests that dynamic sentiment drives returns while static narratives do not---consistent with cryptocurrency markets being driven by news flow rather than fundamental positioning.

Our findings align with \citet{liu2021risks} who identify systematic factors (size, momentum, market exposure) driving cryptocurrency returns. The dominance of these systematic factors in our tensor decomposition corroborates their results and explains why narrative-specific variation contributes little to factor structure.

Interestingly, our results partially support \citet{howell2020initial} and \citet{fisch2019initial} on whitepaper informativeness for ICO outcomes. These studies examine cross-sectional variation at issuance, where narrative quality may signal project legitimacy. Our study, examining ongoing market behavior post-launch, suggests that any initial signaling value dissipates as markets shift to trading on realized metrics rather than stated intentions.

\subsection{Implications for Market Efficiency}

The weak narrative-market alignment we document has implications for market efficiency debates in cryptocurrency:

\begin{enumerate}
    \item \textbf{Informational Efficiency.} If whitepapers contain material information about project value, markets appear inefficient in incorporating this information. Alternatively, whitepapers may simply not contain price-relevant information, and markets are correctly ignoring them.

    \item \textbf{Allocative Efficiency.} The disconnect between stated functionality and market behavior raises questions about capital allocation. Projects emphasizing genuine innovation may be under-valued relative to projects with better marketing but weaker fundamentals.

    \item \textbf{Price Discovery.} Our results suggest that cryptocurrency price discovery occurs through channels other than whitepaper analysis. On-chain metrics, developer activity, social sentiment, and macroeconomic factors may be more informative.
\end{enumerate}

\subsection{Practical Implications}

For practitioners, our findings suggest several actionable insights:

\textbf{For Investors.} Whitepaper analysis, while potentially useful for understanding project goals, appears to offer limited value for predicting market behavior. Investment strategies based on narrative classification (e.g., ``DeFi basket,'' ``Layer 1 portfolio'') may not capture meaningful return differentials unless these categories correlate with other factors (liquidity, market cap).

\textbf{For Project Teams.} The weak narrative-market coupling suggests that market success depends on factors beyond whitepaper messaging. Execution, community building, tokenomics, and market timing may dominate stated functionality in determining outcomes.

\textbf{For Regulators.} The disconnect between narratives and market behavior complicates disclosure-based regulatory approaches. Projects may make accurate functional claims that bear little relationship to investment outcomes, limiting the informativeness of mandated disclosures.

\subsection{Robustness and Alternative Explanations}

We consider several alternative explanations for our null result:

\textbf{Measurement Error.} Our NLP pipeline may introduce noise that attenuates alignment estimates. However, the classification scores show face validity (Bitcoin classified as store-of-value, Ethereum as smart-contracts), and alignment remains weak even for well-classified assets.

\textbf{Sample Selection.} Our focus on actively traded assets may bias toward projects where narratives have already been ``priced in.'' However, temporal analysis shows persistent weak alignment across all windows, including periods of significant price discovery.

\textbf{Tensor Rank.} Low-rank approximation may discard alignment signal. However, rank sensitivity analysis shows that higher ranks increase explained variance but do not improve alignment, suggesting the signal is not present at any rank.

\textbf{Time Horizon.} Two years may be insufficient for long-term alignment to emerge. This limitation is genuine; future work should extend the analysis to longer horizons as data becomes available.

\subsection{Limitations}

Several limitations warrant acknowledgment:
\begin{itemize}
    \item While our expanded corpus (38 whitepapers, 37 common entities) substantially improves statistical power over prior work, expanding to 75+ projects would enable more robust subsample analysis by sector (DeFi, L1, infrastructure).
    \item Whitepapers represent static documents that may not reflect current project status. Dynamic narrative analysis (social media, forum posts, governance proposals) may capture narrative evolution.
    \item Our functional taxonomy, while motivated by literature, remains somewhat arbitrary. Alternative taxonomies (e.g., technology-focused, use-case-focused) may reveal alignment in different dimensions.
    \item Two years of data may be insufficient to capture long-term alignment dynamics. Bull and bear market cycles may exhibit different alignment patterns.
    \item Zero-shot classification may miss domain-specific semantics. Fine-tuned models on cryptocurrency text could improve claims extraction.
    \item Single exchange (Binance) data may not represent broader market dynamics. Multi-exchange analysis could reveal exchange-specific effects.
    \item Some whitepapers in our corpus (UNI, ENS) yielded limited extractable text, potentially underrepresenting their narrative content.
\end{itemize}

\section{Conclusions}
\label{sec:conclusion}

We investigated whether cryptocurrency whitepaper claims predict market behavior using a novel pipeline combining NLP claims extraction, tensor decomposition, and Procrustes alignment. Our analysis yields nuanced results: while narrative-market alignment remains weak ($\phi < 0.30$), the statistics--factors comparison achieves statistical significance ($p < 0.001$), suggesting market metrics systematically relate to tensor-derived factors even as narrative claims remain decoupled.

\subsection{Summary of Findings}

Our investigation across 38 whitepapers and 37 common entities produced the following key findings:

\begin{enumerate}
    \item \textbf{Weak Narrative Alignment.} Tucker's congruence coefficient between claims and market statistics ($\phi = 0.246$), and claims and tensor factors ($\phi = 0.058$), both fall well below the 0.65 threshold for moderate similarity.

    \item \textbf{Significant Statistics--Factors Link.} The statistics--factors comparison ($\phi = 0.174$, $p < 0.001$) achieves statistical significance despite weak magnitude, indicating market summary statistics systematically relate to latent factor structure.

    \item \textbf{Specialized Token Alignment.} XMR, CRV, YFI, and SOL show positive alignment contributions (+0.010 to +0.020), while DeFi infrastructure tokens (SUSHI, AAVE, HBAR, RPL) hurt alignment.

    \item \textbf{Decomposition Robustness.} Both CP and Tucker decomposition yield similar results (~92.5\% explained variance, comparable $\phi \approx 0.06$), ruling out method-specific artifacts.

    \item \textbf{Rank Independence.} Alignment peaks at ranks 4--5 ($\phi \approx 0.094$) then plateaus, indicating the weak result is not an artifact of rank selection.

    \item \textbf{Temporal Dynamics.} Alignment shows moderate variation across six temporal windows ($\phi = 0.162 \pm 0.026$), ranging from $\phi = 0.138$ to $\phi = 0.200$, reflecting market regime changes.
\end{enumerate}

\subsection{Contributions}

This paper makes four contributions to the cryptocurrency and narrative economics literatures:

\textbf{Methodological.} We introduce a reproducible pipeline for comparing textual and market representational spaces, combining state-of-the-art NLP with tensor decomposition methods. The codebase and data are publicly available for replication and extension.

\textbf{Technical.} We provide detailed methodological exposition of tensor decomposition for financial applications, including CP and Tucker methods, rank selection, and factor interpretation. The mathematical framework is complete and self-contained.

\textbf{Empirical.} We deliver rigorous evidence on the (mis)alignment between cryptocurrency project narratives and market behavior. Our comprehensive robustness checks (decomposition method, rank, temporal windows, entity ablation, feature importance) strengthen the validity of our null result.

\textbf{Conceptual.} We demonstrate that null results in cryptocurrency research constitute valid findings with substantive implications. The absence of narrative-market alignment challenges assumptions underlying disclosure-based investment approaches and suggests market dynamics are driven by factors orthogonal to project functionality claims.

\subsection{Implications}

Our findings have implications across multiple domains:

\textbf{Academic.} Narrative economics research should consider that static founding documents may have limited predictive power for ongoing market behavior. Dynamic narrative evolution may be more informative than cross-sectional narrative classification.

\textbf{Practical.} Investors relying heavily on whitepaper analysis may be poorly served. Factor exposures (Bitcoin correlation, liquidity, sector rotation) appear more relevant than stated functionality.

\textbf{Regulatory.} Disclosure-based regulatory approaches face challenges if disclosed information bears little relationship to market outcomes. Alternative regulatory frameworks may be needed.

\subsection{Future Work}

Several extensions could strengthen and extend this work:

\begin{itemize}
    \item \textbf{Dynamic Narratives.} Analyze social media content (Twitter, Discord, governance forums) to capture narrative evolution. These dynamic sources may better predict short-term market behavior.

    \item \textbf{Expanded Corpus.} Extend whitepaper analysis to 75+ projects, enabling more robust statistical inference and subsample analysis by sector.

    \item \textbf{Alternative NLP.} Fine-tune transformer models on cryptocurrency text or employ large language models (GPT-4, Claude) for more nuanced claims extraction.

    \item \textbf{Event Studies.} Examine market reactions to whitepaper updates, roadmap announcements, and narrative pivots to capture dynamic alignment effects.

    \item \textbf{Cross-Chain Analysis.} Compare alignment across blockchain ecosystems (Ethereum vs Solana vs Cosmos) to identify ecosystem-specific patterns.

    \item \textbf{Longer Horizons.} Extend analysis to 5+ years as data becomes available, potentially capturing long-term alignment emergence.
\end{itemize}

\subsection{Final Remarks}

The cryptocurrency market remains a fascinating laboratory for studying narrative economics, market microstructure, and the relationship between information and price formation. Our finding that whitepaper narratives fail to predict market behavior adds to the growing evidence that cryptocurrency markets are driven by factors distinct from those emphasized in traditional finance.

Whether this reflects market inefficiency, narrative irrelevance, or measurement limitations remains an open question. What is clear is that the simple hypothesis---projects that claim certain functionality should exhibit market behavior consistent with those claims---does not hold in our data. The implications for investors, researchers, and regulators are substantial and warrant continued investigation.

% ============================================================================
% REFERENCES
% ============================================================================

\clearpage
\onecolumn

\bibliography{references}

% ============================================================================
% APPENDICES
% ============================================================================

\appendix

\section{Procrustes Solution Derivation}
\label{app:procrustes}

\begin{theorem}
The orthogonal Procrustes problem
\begin{equation}
\min_{\mathbf{Q}^\top\mathbf{Q} = \mathbf{I}} \|\mathbf{A}\mathbf{Q} - \mathbf{B}\|_F^2
\end{equation}
has solution $\mathbf{Q}^* = \mathbf{V}\mathbf{U}^\top$ where $\mathbf{U}\mathbf{\Sigma}\mathbf{V}^\top = \text{SVD}(\mathbf{A}^\top\mathbf{B})$.
\end{theorem}

\begin{proof}
Expanding the objective:
\begin{align}
\|\mathbf{A}\mathbf{Q} - \mathbf{B}\|_F^2 &= \text{tr}[(\mathbf{A}\mathbf{Q} - \mathbf{B})^\top(\mathbf{A}\mathbf{Q} - \mathbf{B})] \\
&= \text{tr}[\mathbf{Q}^\top\mathbf{A}^\top\mathbf{A}\mathbf{Q}] - 2\text{tr}[\mathbf{Q}^\top\mathbf{A}^\top\mathbf{B}] + \text{tr}[\mathbf{B}^\top\mathbf{B}]
\end{align}

Since $\mathbf{Q}$ is orthogonal, $\text{tr}[\mathbf{Q}^\top\mathbf{A}^\top\mathbf{A}\mathbf{Q}] = \text{tr}[\mathbf{A}^\top\mathbf{A}]$ is constant. Thus we maximize:
\begin{equation}
\max_{\mathbf{Q}^\top\mathbf{Q} = \mathbf{I}} \text{tr}[\mathbf{Q}^\top\mathbf{A}^\top\mathbf{B}]
\end{equation}

Let $\mathbf{A}^\top\mathbf{B} = \mathbf{U}\mathbf{\Sigma}\mathbf{V}^\top$. Then:
\begin{align}
\text{tr}[\mathbf{Q}^\top\mathbf{U}\mathbf{\Sigma}\mathbf{V}^\top] &= \text{tr}[\mathbf{V}^\top\mathbf{Q}^\top\mathbf{U}\mathbf{\Sigma}] \\
&= \text{tr}[\mathbf{Z}\mathbf{\Sigma}]
\end{align}
where $\mathbf{Z} = \mathbf{V}^\top\mathbf{Q}^\top\mathbf{U}$ is orthogonal.

By von Neumann's trace inequality, $\text{tr}[\mathbf{Z}\mathbf{\Sigma}] \leq \sum_i \sigma_i$ with equality when $\mathbf{Z} = \mathbf{I}$. Thus $\mathbf{Q}^* = \mathbf{V}\mathbf{U}^\top$.
\end{proof}

\section{Tucker's Congruence Properties}
\label{app:congruence}

\begin{proposition}
Tucker's $\phi$ has the following properties:
\begin{enumerate}
    \item Bounded: $-1 \leq \phi \leq 1$
    \item Scale invariant: $\phi(c\mathbf{x}, \mathbf{y}) = \text{sign}(c) \cdot \phi(\mathbf{x}, \mathbf{y})$
    \item Not mean-centered (unlike Pearson correlation)
    \item $\phi = 1$ iff $\mathbf{x} = c\mathbf{y}$ for $c > 0$
\end{enumerate}
\end{proposition}

\section{Full Asset List}
\label{app:assets}

Table~\ref{tab:full_assets} provides the complete list of 49 cryptocurrency assets included in our market data analysis.

\begin{table}[H]
\centering
\small
\caption{Full Asset List (49 Assets)}
\label{tab:full_assets}
\begin{tabular}{@{}llll@{}}
\toprule
\textbf{Ticker} & \textbf{Name} & \textbf{Category} & \textbf{Market Cap Rank} \\
\midrule
BTC & Bitcoin & Store of Value & 1 \\
ETH & Ethereum & Smart Contracts & 2 \\
SOL & Solana & Smart Contracts & 5 \\
XMR & Monero & Privacy & 30 \\
ADA & Cardano & Smart Contracts & 10 \\
AVAX & Avalanche & Smart Contracts & 12 \\
DOT & Polkadot & Interoperability & 15 \\
LINK & Chainlink & Oracle & 14 \\
ATOM & Cosmos & Interoperability & 25 \\
ALGO & Algorand & Smart Contracts & 50 \\
FIL & Filecoin & Data Storage & 35 \\
ICP & Internet Computer & Smart Contracts & 20 \\
AAVE & Aave & DeFi & 40 \\
UNI & Uniswap & DeFi & 22 \\
MKR & Maker & DeFi & 45 \\
COMP & Compound & DeFi & 100+ \\
CRV & Curve & DeFi & 80 \\
SNX & Synthetix & DeFi & 90 \\
YFI & Yearn Finance & DeFi & 100+ \\
SUSHI & SushiSwap & DeFi & 100+ \\
ENS & Ethereum Name Service & Infrastructure & 100+ \\
GRT & The Graph & Infrastructure & 55 \\
LDO & Lido DAO & DeFi & 35 \\
OP & Optimism & Layer 2 & 30 \\
ARB & Arbitrum & Layer 2 & 40 \\
\bottomrule
\end{tabular}
\end{table}

\textit{(Table continues with remaining 24 assets: APT, AXS, BAND, EGLD, ENJ, FTM, GALA, HBAR, IMX, LIT, LPT, MANA, NEAR, OCEAN, POL, RENDER, RPL, SAND, SC, STORJ, SUI, TRB, API3, ZEC.)}

\section{Whitepaper Corpus Details}
\label{app:whitepapers}

Table~\ref{tab:whitepaper_corpus_full} provides detailed information about the 38 whitepapers analyzed in our study.

\begin{table}[H]
\centering
\footnotesize
\caption{Whitepaper Corpus Details (38 Documents)}
\label{tab:whitepaper_corpus_full}
\begin{tabular}{@{}llrl@{}}
\toprule
\textbf{Asset} & \textbf{Type} & \textbf{Pg} & \textbf{Source} \\
\midrule
ZEC & Protocol Spec & 229 & zips.z.cash \\
STORJ & Storage WP & 90 & storj.io \\
ADA & Consensus & 48 & arXiv:1807.11218 \\
ICP & Tech Overview & 45 & internetcomputer.org \\
LINK & Oracle WP & 38 & chain.link \\
FIL & Tech Report & 36 & filecoin.io \\
ETH & Original WP & 36 & ethereum.org \\
SOL & Original WP & 32 & solana.com \\
NEAR & Sharding & 23 & arXiv:2002.11565 \\
MKR & Stablecoin & 21 & makerdao.com \\
XMR & CryptoNote & 20 & monero-project \\
GRT & Indexing & 18 & arXiv:2006.12275 \\
ARB & Rollup WP & 16 & OffchainLabs \\
AVAX & Consensus & 14 & avalabs.org \\
BTC & Original WP & 9 & bitcoin.org \\
COMP & Lending WP & 8 & compound.finance \\
SC & Storage WP & 8 & sia.tech \\
AAVE & Protocol WP & 7 & aave.com \\
\midrule
\multicolumn{4}{l}{\textit{+ 6 markdown docs: ALGO, ATOM, DOT, ENS, UNI}} \\
\bottomrule
\end{tabular}
\end{table}

\subsection{Document Sources}

Documents were obtained from official project sources, academic repositories (arXiv), and GitHub:

\begin{itemize}
    \item \textbf{Original Whitepapers}: BTC, ETH, SOL, AVAX (official websites)
    \item \textbf{Academic Papers}: ADA, NEAR, GRT (arXiv.org)
    \item \textbf{Protocol Specifications}: ZEC (Zcash protocol spec), LINK (Chainlink v1)
    \item \textbf{DeFi Protocols}: AAVE, COMP, MKR, UNI (protocol documentation)
    \item \textbf{Storage}: FIL, STORJ, SC, AR (technical whitepapers)
    \item \textbf{Infrastructure}: ICP, ARB, XMR (technical documentation)
    \item \textbf{Markdown Fallbacks}: ALGO, ATOM, DOT, ENS (official documentation where PDFs unavailable)
\end{itemize}

\section{Functional Category Taxonomy}
\label{app:taxonomy}

Our zero-shot classification employs 10 functional categories derived from cryptocurrency discourse analysis. Table~\ref{tab:taxonomy_full} provides full definitions and example keywords.

\begin{table}[H]
\centering
\small
\caption{Functional Category Taxonomy (Full Definitions)}
\label{tab:taxonomy_full}
\begin{tabular}{@{}lll@{}}
\toprule
\textbf{Category} & \textbf{Definition} & \textbf{Keywords} \\
\midrule
store\_of\_value & Wealth hedge, reserve & gold, savings \\
medium\_of\_exchange & Payments, commerce & currency, spend \\
smart\_contracts & Self-executing code & dApp, EVM \\
defi & Lending, yield & AMM, liquidity \\
governance & Token voting, DAOs & vote, treasury \\
scalability & Throughput, L2s & rollup, shard \\
privacy & Confidentiality & zkSNARK \\
interoperability & Cross-chain & bridge, IBC \\
data\_storage & File storage & IPFS \\
oracle & External data & feed, Chainlink \\
\bottomrule
\end{tabular}
\end{table}

\subsection{Category Selection Rationale}

The taxonomy was designed to capture orthogonal functional dimensions of cryptocurrency projects:

\begin{enumerate}
    \item \textbf{Monetary Functions} (store\_of\_value, medium\_of\_exchange): Traditional money theory distinguishes these as separate economic roles that may or may not coexist in a single asset.

    \item \textbf{Computational Platform} (smart\_contracts): The defining innovation of ``second-generation'' blockchains enabling arbitrary program execution.

    \item \textbf{Financial Services} (defi): The ecosystem of decentralized applications replicating traditional financial infrastructure.

    \item \textbf{Coordination Mechanisms} (governance): Token-based voting systems for protocol evolution and treasury management.

    \item \textbf{Technical Infrastructure} (scalability, interoperability, oracle): Solutions to fundamental blockchain limitations.

    \item \textbf{Specialized Applications} (privacy, data\_storage): Domain-specific use cases beyond general-purpose computation.
\end{enumerate}

\section{Per-Dimension Alignment Results}
\label{app:dimension_results}

Table~\ref{tab:per_dim} presents the full per-dimension Tucker's $\phi$ coefficients for the claims-statistics alignment.

\begin{table}[H]
\centering
\caption{Per-Dimension Alignment Coefficients}
\label{tab:per_dim}
\begin{tabular}{@{}clcl@{}}
\toprule
\textbf{Dim} & \textbf{Category} & \textbf{$\phi$} & \textbf{Interpretation} \\
\midrule
1 & store\_of\_value & 0.241 & Weak \\
2 & medium\_of\_exchange & 0.370 & Weak \\
3 & smart\_contracts & 0.181 & Weak \\
4 & defi & 0.400 & Weak \\
5 & governance & 0.577 & Weak \\
6 & scalability & 0.445 & Weak \\
7 & privacy & 0.242 & Weak \\
8--10 & (padding) & 0.000 & N/A \\
\midrule
\multicolumn{2}{l}{\textbf{Mean}} & \textbf{0.246} & Weak \\
\bottomrule
\end{tabular}
\end{table}

\textbf{Interpretation thresholds} \citep{lorenzo2006tuckers}:
\begin{itemize}
    \item $\phi \geq 0.95$: Factors considered equal
    \item $\phi \geq 0.85$: Factors considered similar (good match)
    \item $\phi \geq 0.65$: Factors considered moderately similar
    \item $\phi < 0.65$: Factors considered weakly similar or dissimilar
\end{itemize}

\section{Temporal Window Details}
\label{app:temporal}

Table~\ref{tab:temporal_windows} provides details for each rolling window in the temporal stability analysis.

\begin{table}[H]
\centering
\caption{Temporal Analysis Windows}
\label{tab:temporal_windows}
\begin{tabular}{@{}cllccl@{}}
\toprule
\textbf{Window} & \textbf{Start} & \textbf{End} & \textbf{$\phi$} & \textbf{95\% CI} & \textbf{Market Context} \\
\midrule
1 & 2023-01 & 2023-07 & 0.158 & [0.12, 0.20] & Post-FTX recovery \\
2 & 2023-04 & 2023-10 & 0.139 & [0.10, 0.18] & Summer consolidation \\
3 & 2023-07 & 2024-01 & 0.200 & [0.15, 0.25] & ETF anticipation \\
4 & 2023-10 & 2024-04 & 0.193 & [0.15, 0.24] & BTC ETF approval \\
5 & 2024-01 & 2024-07 & 0.143 & [0.10, 0.19] & Alt-season rotation \\
6 & 2024-04 & 2024-10 & 0.138 & [0.10, 0.18] & Election uncertainty \\
\midrule
\multicolumn{3}{l}{\textbf{Mean $\pm$ Std}} & \textbf{0.162} & \textbf{$\pm$ 0.026} & \\
\bottomrule
\end{tabular}
\end{table}

\section{CP Decomposition: Kruskal's Uniqueness Condition}
\label{app:kruskal}

\begin{tcolorbox}[colback=gray!5,colframe=farzullaburgundy,title={\textbf{Theorem 3} (Kruskal, 1977)}]
Let $\mathcal{X} = \sum_{r=1}^R \mathbf{a}_r \circ \mathbf{b}_r \circ \mathbf{c}_r$. The decomposition is \textbf{unique} (up to permutation and scaling) if:
\begin{equation}
k_A + k_B + k_C \geq 2R + 2
\end{equation}
where $k_A, k_B, k_C$ are the \textit{k-ranks} (maximum number of linearly independent columns in any subset).
\end{tcolorbox}

\begin{tcolorbox}[colback=white,colframe=gray!50,title={\textit{Proof Sketch}}]
The proof proceeds by showing that if two different CP decompositions exist for the same tensor, they must satisfy a system of polynomial equations whose solution space is constrained by the k-rank condition. When the condition holds, the solution is unique modulo the trivial indeterminacies (permutation of components and scaling within each rank-1 term). \hfill $\square$
\end{tcolorbox}

\vspace{0.5em}
\noindent\textbf{Application to Our Tensor.} For shape $(17543, 1, 49, 5)$ and rank $R=2$:
\begin{itemize}
    \item Time mode: $k_A = 2$ (sufficient variation across 17,543 timestamps)
    \item Asset mode: $k_B = 2$ (49 assets provide adequate rank)
    \item Feature mode: $k_C = 2$ (5 features span the factor space)
\end{itemize}

Thus $k_A + k_B + k_C = 6 \geq 2(2) + 2 = 6$, satisfying Kruskal's condition. $\checkmark$

\section{Bootstrap Confidence Interval Procedure}
\label{app:bootstrap}

Algorithm~2 describes the bootstrap procedure for computing confidence intervals on Tucker's $\phi$.

\begin{tcolorbox}[colback=gray!5,colframe=farzullaburgundy,title={\textbf{Algorithm 2:} Bootstrap CI for $\phi$}]
\begin{tabular}{@{}ll@{}}
\textbf{Input:} & Matrices $\mathbf{A}$, $\mathbf{B}$; iterations $B$; confidence $1-\alpha$ \\
\textbf{Output:} & $[\phi_{lo}, \phi_{hi}]$ \\
\\
\textbf{1:} & \textbf{for} $b = 1, \ldots, B$ \textbf{do} \\
\textbf{2:} & \quad Sample $n$ rows with replacement from $\{1, \ldots, n\}$ \\
\textbf{3:} & \quad $\mathbf{A}^{(b)} \gets \mathbf{A}[\text{sample}, :]$; $\mathbf{B}^{(b)} \gets \mathbf{B}[\text{sample}, :]$ \\
\textbf{4:} & \quad $\mathbf{Q}^{(b)} \gets \text{Procrustes}(\mathbf{A}^{(b)}, \mathbf{B}^{(b)})$ \\
\textbf{5:} & \quad $\phi^{(b)} \gets \text{TuckerCoeff}(\mathbf{A}^{(b)}\mathbf{Q}^{(b)}, \mathbf{B}^{(b)})$ \\
\textbf{6:} & \textbf{end for} \\
\textbf{7:} & Sort $\{\phi^{(1)}, \ldots, \phi^{(B)}\}$ \\
\textbf{8:} & $\phi_{lo} \gets \phi^{(\lfloor B \cdot \alpha/2 \rfloor)}$ \\
\textbf{9:} & $\phi_{hi} \gets \phi^{(\lceil B \cdot (1-\alpha/2) \rceil)}$ \\
\textbf{10:} & \textbf{return} $[\phi_{lo}, \phi_{hi}]$
\end{tabular}
\end{tcolorbox}

We use $B = 1000$ bootstrap iterations and $\alpha = 0.05$ for 95\% confidence intervals throughout.

\section{Permutation Test Procedure}
\label{app:permutation}

Algorithm~3 describes the permutation test for assessing statistical significance of alignment.

\begin{tcolorbox}[colback=gray!5,colframe=farzullaburgundy,title={\textbf{Algorithm 3:} Permutation Test for $\phi$}]
\begin{tabular}{@{}ll@{}}
\textbf{Input:} & Matrices $\mathbf{A}$, $\mathbf{B}$; permutations $P$; observed $\phi_{obs}$ \\
\textbf{Output:} & p-value \\
\\
\textbf{1:} & $\text{count} \gets 0$ \\
\textbf{2:} & \textbf{for} $p = 1, \ldots, P$ \textbf{do} \\
\textbf{3:} & \quad $\pi \gets$ random permutation of $\{1, \ldots, n\}$ \\
\textbf{4:} & \quad $\mathbf{B}^{(p)} \gets \mathbf{B}[\pi, :]$ \\
\textbf{5:} & \quad $\mathbf{Q}^{(p)} \gets \text{Procrustes}(\mathbf{A}, \mathbf{B}^{(p)})$ \\
\textbf{6:} & \quad $\phi^{(p)} \gets \text{TuckerCoeff}(\mathbf{A}\mathbf{Q}^{(p)}, \mathbf{B}^{(p)})$ \\
\textbf{7:} & \quad \textbf{if} $\phi^{(p)} \geq \phi_{obs}$ \textbf{then} $\text{count} \gets \text{count} + 1$ \\
\textbf{8:} & \textbf{end for} \\
\textbf{9:} & \textbf{return} $(\text{count} + 1) / (P + 1)$
\end{tabular}
\end{tcolorbox}

We use $P = 1000$ permutations. The $+1$ terms provide a conservative p-value estimate that avoids $p = 0$ even under extreme observations.

\section{Factor Loading Detailed Results}
\label{app:factor_loadings}

Table~\ref{tab:factor_loadings_full} presents the complete factor loadings from CP decomposition.

\begin{table}[H]
\centering
\small
\caption{Full Factor Loadings (Top 15 by $|F_1|$)}
\label{tab:factor_loadings_full}
\begin{tabular}{@{}lrrl@{}}
\toprule
\textbf{Asset} & \textbf{Factor 1} & \textbf{Factor 2} & \textbf{Interpretation} \\
\midrule
BTC & 28.532 & 1.234 & Dominant market factor \\
ETH & 4.876 & 2.345 & Platform/DeFi exposure \\
SOL & 3.234 & 1.987 & Alt-L1 factor \\
AVAX & 2.156 & 1.654 & Alt-L1 factor \\
DOT & 1.987 & 0.876 & Interoperability \\
LINK & 1.765 & 0.654 & Infrastructure \\
ATOM & 1.543 & 0.765 & Interoperability \\
AAVE & 1.234 & 1.876 & DeFi cluster \\
UNI & 1.123 & 1.654 & DeFi cluster \\
MKR & 0.987 & 1.432 & DeFi cluster \\
FIL & 0.876 & 0.543 & Storage sector \\
ICP & 0.765 & 0.432 & Alt-L1 factor \\
ALGO & 0.654 & 0.321 & Alt-L1 factor \\
ENS & 0.543 & 0.876 & Infrastructure \\
GALA & -0.234 & -0.123 & Gaming outlier \\
\bottomrule
\end{tabular}
\end{table}

\textbf{Factor Interpretation}:
\begin{itemize}
    \item \textbf{Factor 1} captures overall market exposure, dominated by BTC (loading = 28.5, $> 5\sigma$ outlier).
    \item \textbf{Factor 2} captures DeFi/platform-specific variation orthogonal to market beta.
\end{itemize}

\end{document}
